ls(0)
ls()
version
ls()
version
packageName()
package_version(ggplot2)
package_version(sqldf)
package_version(dplyr)
license()
version
license
license()
library(gmodels)
library(caret)
library(vcd)
library(ROCR)
library(C50)
library(irr)  ## for kappa statistics
## Evaluating model performance...
sms_results = read.csv("C:/CezarFiles/MachineLearningWithR/Chapter10/sms_results.csv")
install.packages("gmodels")
install.packages("caret")
install.packages("vcd")
install.packages("ROCR")
install.packages("C50")
install.packages("irr")
library(gmodels)
library(caret)
library(vcd)
library(ROCR)
library(C50)
library(irr)  ## for kappa statistics
## Evaluating model performance...
sms_results = read.csv("C:/CezarFiles/MachineLearningWithR/Chapter10/sms_results.csv")
## confusion matrix...
table(sms_results$actual_type, sms_results$predict_type) ## simple confusion matrix
CrossTable(sms_results$actual_type, sms_results$predict_type)  ## detailed confusion matrix
confusionMatrix(sms_results$predict_type, sms_results$actual_type, positive = "spam") ## from caret package
Kappa(table(sms_results$actual_type, sms_results$predict_type)) ## Kappa from vcd package
## sensitivity and specificity...from caret package
sensitivity(sms_results$predict_type, sms_results$actual_type, positive = "spam")
specificity(sms_results$predict_type, sms_results$actual_type, negative = "ham")
## precision and recall...from caret package
posPredValue(sms_results$predict_type, sms_results$actual_type, positive = "spam")
## precision and recall...from caret package
posPredValue(sms_results$predict_type, sms_results$actual_type, positive = "spam")
## ROCR package prediction function for use in perf. visualizations...
pred = prediction(predictions = sms_results$prob_spam, labels = sms_results$actual_type)
perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, main = "ROC curve for SMS spam filter", col = "blue", lwd = 3)
abline(a = 0, b = 1, lwd = 2, lty = 2)
perf.auc = performance(pred, measure = "auc")
unlist(perf.auc@y.values)
## Creating random samples...training, validation and test (50,25,25)...
credit = read.csv("C:/SBD_Files/Timesheets/Readings/2148OS_code/chapter 10/credit.csv")
random_ids = order(runif(1000))
credit_train = credit[random_ids[1:500],]
credit_validate = credit[random_ids[501:750], ]
credit_test = credit[random_ids[751:1000], ]
## Creating stratified sampling using the caret package...
in_train = createDataPartition(credit$default, p = 0.75, list = FALSE)
credit_train = credit[in_train, ]
credit_test = credit[-in_train, ]
## K-folds cross validation using caret package...
folds = createFolds(credit$default, k = 10)
credit01_train = credit[-folds$Fold01, ]
credit01_test = credit[folds$Fold01, ]
## Applying K-folds to credit data and measure kappa...
set.seed(123)
folds = createFolds(credit$default, k = 10)
## Creating random samples...training, validation and test (50,25,25)...
credit = read.csv("C:/CezarFiles/MachineLearningWithR/Chapter10/credit.csv")
random_ids = order(runif(1000))
credit_train = credit[random_ids[1:500],]
credit_validate = credit[random_ids[501:750], ]
credit_test = credit[random_ids[751:1000], ]
## Creating stratified sampling using the caret package...
in_train = createDataPartition(credit$default, p = 0.75, list = FALSE)
credit_train = credit[in_train, ]
credit_test = credit[-in_train, ]
## K-folds cross validation using caret package...
folds = createFolds(credit$default, k = 10)
credit01_train = credit[-folds$Fold01, ]
credit01_test = credit[folds$Fold01, ]
## Applying K-folds to credit data and measure kappa...
set.seed(123)
folds = createFolds(credit$default, k = 10)
library(caret)
credit = read.csv("C:/CezarFiles/MachineLearningWithR/Chapter11/credit.csv")
set.seed(300)
m = train(default ~ ., data = credit, method = "C5.0")
summary(m)
m
m = train(default ~ ., data = credit, method = "C5.0")
library(e1071)
install.packages("e1071")
m = train(default ~ ., data = credit, method = "C5.0")
m
set.seed(300)
m = train(default ~ ., data = credit, method = "C5.0")
m
m$finalModel
p = predict(m, credit)
class(p)
head(p)
table(p, credit$default)
head(predict(p, credit$default))
head(predict(m, credit$default))
head(predict(m, credit))
head(predict(m, credit, type = "prob"))
ctrl = trainControl(method = "cv", number = 10, selectionFunction = "oneSE")
class(ctrl)
ctrl
grid = expand.grid(.model = "tree", .trials = c(1,5,10,15.20,25,30,35), .winnow = "FALSE")
grid
grid = expand.grid(.model = "tree", .trials = c(1,5,10,15,20,25,30,35), .winnow = "FALSE")
grid
m = train(default ~ ., data = credit, method = "C5.0", metric = "Kappa",
trControl = ctrl, tuneGrid = grid)
m
install.packages("checkpoint")
library(checkpoint)
checkpoint("2017-01-24", R.version = "3.3.2")
checkpoint("2017-01-24", R.version = "3.3.1")
library(MASS)
## install.packages("checkpoint")
library(checkpoint)
checkpoint("2017-01-24", R.version = "3.3.1")
## Chapter 1
library(RCurl)
library(jsonlite)
library(caret)
library(e1071)
## basic stats package
library(statmod)
library(MASS)
## install.packages("checkpoint")
library(checkpoint)
checkpoint("2017-01-24", R.version = "3.3.1")
## Chapter 1
library(RCurl)
library(jsonlite)
library(caret)
library(e1071)
## basic stats package
library(statmod)
library(MASS)
## neural networks
library(nnet)
library(neuralnet)
library(RSNNS)
install.packages("statmod")
library(checkpoint)
library(RCurl)
checkpoint("2017-01-24", R.version = "3.3.1")
library(RCurl)
library(jsonlite)
library(caret)
install.packages("caret", dep=T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
library(caret)
library(caret)
install.packages("caret")
install.packages("caret")
library(caret)
library(caret)
library(caret)
library(e1071)
## basic stats package
library(statmod)
install.packages("statmod")
library(statmod)
library(MASS)
## neural networks
library(nnet)
library(neuralnet)
install.packages("neuralnet")
library(neuralnet)
library(RSNNS)
install.packages("RSNNS")
library(RSNNS)
checkpoint("2017-01-24", R.version = "3.3.1")
library(checkpoint)
checkpoint("2017-01-24", R.version = "3.3.1")
library(deepnet)
install.packages("deepnet")
library(deepnet)
checkpoint("2017-01-24", R.version = "3.3.1")
library(darch)
checkpoint("2017-01-24", R.version = "3.3.1")
install.packages("darch")
library(darch)
install.packages("h2o")
c1 = h2o.init(max_mem_size = "3G", nthreads = 2)
library(h2o)
c1 = h2o.init(max_mem_size = "3G", nthreads = 2)
library(h2o)
h2o.init(nthreads = -1, max_mem_size = "2G")
h20.removeAll()
h2o.removeAll()
h2o.init(nthreads = nthreads = 2, max_mem_size = "3G")
h2o.init(nthreads = 2, max_mem_size = "3G")
h2o.removeAll()
h2o.init(nthreads = 2, max_mem_size = "3G")
h2oiris = as.h2o(droplevels(iris[1:100,]))
h2oiris
str(h2oiris)
class(h2oiris)
h20.levels(h20iris, 5)
h2o.levels(h20iris, 5)
h2o.levels(h20oiris, 5)
h2o.levels(h2oiris, 5)
setwd("C:\CezarFiles\DeepLearningEssentials-R")
setwd("C:/CezarFiles/DeepLearningEssentials-R")
getwd()
write.csv(mtcars, file = "mtcars.csv")
h2omtcars = h2o.import(path = "mtcars.csv")
h2omtcars = h2o.importFile(path = "mtcars.csv")
h2omtcars = h2o.importFile(path = "C:/CezarFiles/DeepLearningEssentials-R/mtcars.csv")
h2omtcars
h2obin = h2o.importFile(path = "http://www.ats.ucla.edu/stat/data/binary.csv")
h2obin
