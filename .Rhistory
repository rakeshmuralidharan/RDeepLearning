ls(0)
ls()
version
ls()
version
packageName()
package_version(ggplot2)
package_version(sqldf)
package_version(dplyr)
license()
version
license
license()
library(gmodels)
library(caret)
library(vcd)
library(ROCR)
library(C50)
library(irr)  ## for kappa statistics
## Evaluating model performance...
sms_results = read.csv("C:/CezarFiles/MachineLearningWithR/Chapter10/sms_results.csv")
install.packages("gmodels")
install.packages("caret")
install.packages("vcd")
install.packages("ROCR")
install.packages("C50")
install.packages("irr")
library(gmodels)
library(caret)
library(vcd)
library(ROCR)
library(C50)
library(irr)  ## for kappa statistics
## Evaluating model performance...
sms_results = read.csv("C:/CezarFiles/MachineLearningWithR/Chapter10/sms_results.csv")
## confusion matrix...
table(sms_results$actual_type, sms_results$predict_type) ## simple confusion matrix
CrossTable(sms_results$actual_type, sms_results$predict_type)  ## detailed confusion matrix
confusionMatrix(sms_results$predict_type, sms_results$actual_type, positive = "spam") ## from caret package
Kappa(table(sms_results$actual_type, sms_results$predict_type)) ## Kappa from vcd package
## sensitivity and specificity...from caret package
sensitivity(sms_results$predict_type, sms_results$actual_type, positive = "spam")
specificity(sms_results$predict_type, sms_results$actual_type, negative = "ham")
## precision and recall...from caret package
posPredValue(sms_results$predict_type, sms_results$actual_type, positive = "spam")
## precision and recall...from caret package
posPredValue(sms_results$predict_type, sms_results$actual_type, positive = "spam")
## ROCR package prediction function for use in perf. visualizations...
pred = prediction(predictions = sms_results$prob_spam, labels = sms_results$actual_type)
perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, main = "ROC curve for SMS spam filter", col = "blue", lwd = 3)
abline(a = 0, b = 1, lwd = 2, lty = 2)
perf.auc = performance(pred, measure = "auc")
unlist(perf.auc@y.values)
## Creating random samples...training, validation and test (50,25,25)...
credit = read.csv("C:/SBD_Files/Timesheets/Readings/2148OS_code/chapter 10/credit.csv")
random_ids = order(runif(1000))
credit_train = credit[random_ids[1:500],]
credit_validate = credit[random_ids[501:750], ]
credit_test = credit[random_ids[751:1000], ]
## Creating stratified sampling using the caret package...
in_train = createDataPartition(credit$default, p = 0.75, list = FALSE)
credit_train = credit[in_train, ]
credit_test = credit[-in_train, ]
## K-folds cross validation using caret package...
folds = createFolds(credit$default, k = 10)
credit01_train = credit[-folds$Fold01, ]
credit01_test = credit[folds$Fold01, ]
## Applying K-folds to credit data and measure kappa...
set.seed(123)
folds = createFolds(credit$default, k = 10)
## Creating random samples...training, validation and test (50,25,25)...
credit = read.csv("C:/CezarFiles/MachineLearningWithR/Chapter10/credit.csv")
random_ids = order(runif(1000))
credit_train = credit[random_ids[1:500],]
credit_validate = credit[random_ids[501:750], ]
credit_test = credit[random_ids[751:1000], ]
## Creating stratified sampling using the caret package...
in_train = createDataPartition(credit$default, p = 0.75, list = FALSE)
credit_train = credit[in_train, ]
credit_test = credit[-in_train, ]
## K-folds cross validation using caret package...
folds = createFolds(credit$default, k = 10)
credit01_train = credit[-folds$Fold01, ]
credit01_test = credit[folds$Fold01, ]
## Applying K-folds to credit data and measure kappa...
set.seed(123)
folds = createFolds(credit$default, k = 10)
library(caret)
credit = read.csv("C:/CezarFiles/MachineLearningWithR/Chapter11/credit.csv")
set.seed(300)
m = train(default ~ ., data = credit, method = "C5.0")
summary(m)
m
m = train(default ~ ., data = credit, method = "C5.0")
library(e1071)
install.packages("e1071")
m = train(default ~ ., data = credit, method = "C5.0")
m
set.seed(300)
m = train(default ~ ., data = credit, method = "C5.0")
m
m$finalModel
p = predict(m, credit)
class(p)
head(p)
table(p, credit$default)
head(predict(p, credit$default))
head(predict(m, credit$default))
head(predict(m, credit))
head(predict(m, credit, type = "prob"))
ctrl = trainControl(method = "cv", number = 10, selectionFunction = "oneSE")
class(ctrl)
ctrl
grid = expand.grid(.model = "tree", .trials = c(1,5,10,15.20,25,30,35), .winnow = "FALSE")
grid
grid = expand.grid(.model = "tree", .trials = c(1,5,10,15,20,25,30,35), .winnow = "FALSE")
grid
m = train(default ~ ., data = credit, method = "C5.0", metric = "Kappa",
trControl = ctrl, tuneGrid = grid)
m
install.packages("checkpoint")
library(checkpoint)
checkpoint("2017-01-24", R.version = "3.3.2")
checkpoint("2017-01-24", R.version = "3.3.1")
library(MASS)
## install.packages("checkpoint")
library(checkpoint)
checkpoint("2017-01-24", R.version = "3.3.1")
## Chapter 1
library(RCurl)
library(jsonlite)
library(caret)
library(e1071)
## basic stats package
library(statmod)
library(MASS)
## install.packages("checkpoint")
library(checkpoint)
checkpoint("2017-01-24", R.version = "3.3.1")
## Chapter 1
library(RCurl)
library(jsonlite)
library(caret)
library(e1071)
## basic stats package
library(statmod)
library(MASS)
## neural networks
library(nnet)
library(neuralnet)
library(RSNNS)
install.packages("statmod")
library(checkpoint)
library(RCurl)
checkpoint("2017-01-24", R.version = "3.3.1")
library(RCurl)
library(jsonlite)
library(caret)
install.packages("caret", dep=T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
install.packages("caret", dep = T)
library(caret)
library(caret)
install.packages("caret")
install.packages("caret")
library(caret)
str(digits.train)
setwd("C:/CezarFiles/DeepLearningEssentials-R")
##source("checkpoint.R")
library(caret)
library(RSNNS)
## Chapter 1
library(RCurl)
library(jsonlite)
library(caret)
library(e1071)
## basic stats package
library(statmod)
library(MASS)
## neural networks
library(nnet)
library(neuralnet)
library(RSNNS)
## deep learning
library(deepnet)
library(darch)
library(h2o)
## read in data and explore the data...
digits.train = read.csv("train.csv")
dim(digits.train)
head(colnames(digits.train), 10)
tail(colnames(digits.train), 10)
head(digits.train[,1:4])
table(digits.train[,1])
digits.train$label = factor(digits.train$label, levels = 0:9)
digits.X = digits.train[1:5000, -1]
digits.y = digits.train[1:5000, 1]
barplot(table(digits.y))
set.seed(1234)
digits.m1 = train(x = digits.X, y = digits.y, method = "nnet",
tuneGrid = expand.grid(.size = c(5), .decay = 0.1),
trControl = trainControl(method = "none"), MaxNWts = 10000,
maxit = 100)
digits.m1 = caret::train(x = digits.X, y = digits.y, method = "nnet",
tuneGrid = expand.grid(.size = c(5), .decay = 0.1),
trControl = trainControl(method = "none"), MaxNWts = 10000,
maxit = 100)
digits.yhat1 = predict(digits.m1)
barplot(table(digits.yhat1))
caret::confusionMatrix(digits.y,digits.yhat1)
## rerun using increased number of hidden neurons...
set.seed(1234)
digits.m2 = train(x = digits.X, y = digits.y, method = "nnet",
tuneGrid = expand.grid(.size = c(10), .decay = 0.1),
trControl = trainControl(method = "none"), MaxNWts = 50000,
maxit = 100)
digits.m2 = caret::train(x = digits.X, y = digits.y, method = "nnet",
tuneGrid = expand.grid(.size = c(10), .decay = 0.1),
trControl = trainControl(method = "none"), MaxNWts = 50000,
maxit = 100)
